## Первый блок
### 1. Уровни логирования

Уровни логирования — это категории, которые используются для классификации сообщений в логах по их важности или типу. Они помогают разработчикам и администраторам фильтровать и анализировать логи в зависимости от ситуации. Наиболее распространённые уровни логирования (например, в стандарте PSR-3 или других системах логирования):

- **DEBUG**: Подробная информация для отладки, полезная на этапе разработки. Например, значения переменных или пошаговое выполнение программы.
- **INFO**: Информационные сообщения о нормальном ходе работы приложения (например, запуск сервиса, успешное выполнение задачи).
- **NOTICE**: Замечания о потенциально важных событиях, которые не являются ошибками, но требуют внимания.
- **WARNING**: Предупреждения о возможных проблемах, которые не прерывают работу приложения (например, устаревшая конфигурация).
- **ERROR**: Ошибки, которые влияют на выполнение части функциональности, но приложение продолжает работать.
- **CRITICAL**: Критические ошибки, требующие немедленного вмешательства (например, сбой важного компонента).
- **ALERT**: Ситуации, требующие срочного реагирования (например, отказ системы).
- **EMERGENCY**: Катастрофические сбои, когда система полностью неработоспособна.

Эти уровни часто используются в связке с ELK-стеком для фильтрации и анализа логов.

---

### 2. Что включает в себя ELK-стек?

ELK-стек — это набор инструментов для централизованного сбора, обработки, хранения и визуализации логов. Аббревиатура ELK расшифровывается как:

- **Elasticsearch**: Поисковый и аналитический движок с открытым исходным кодом, основанный на Apache Lucene. Используется для индексирования, хранения и быстрого поиска логов и данных.
- **Logstash**: Инструмент для сбора, обработки, фильтрации и трансформации логов из различных источников перед отправкой в Elasticsearch.
- **Kibana**: Веб-интерфейс для визуализации данных, хранящихся в Elasticsearch. Позволяет создавать дашборды, графики, диаграммы и выполнять поиск по логам.
- **Beats (опционально)**: Лёгкие агенты (например, Filebeat) для сбора логов и метрик с серверов и отправки их в Logstash или напрямую в Elasticsearch.

ELK-стек часто дополняется Beats, что фактически делает его четырёхкомпонентным стеком. Он широко используется для анализа логов, мониторинга систем и бизнес-аналитики.

---

### 3. Что такое Logstash? Зачем он нужен?

**Logstash** — это инструмент с открытым исходным кодом для сбора, обработки и передачи данных (в основном логов) из различных источников в хранилища, такие как Elasticsearch. Он работает как конвейер обработки данных (data pipeline) и состоит из трёх основных компонентов:

- **Input**: Сбор данных из источников (файлы, базы данных, сетевые протоколы, Beats и т.д.).
- **Filter**: Обработка и трансформация данных (например, парсинг логов, добавление метаданных, фильтрация по условиям).
- **Output**: Отправка обработанных данных в хранилище (Elasticsearch, базы данных, файлы и т.д.).

**Зачем нужен Logstash?**

- **Централизация логов**: Собирает данные из множества источников (серверов, приложений, сетевых устройств).
- **Обработка и нормализация**: Парсит неструктурированные логи (например, с помощью фильтра Grok) и приводит их к единому формату.
- **Фильтрация и обогащение**: Позволяет фильтровать ненужные данные, добавлять гео-данные, преобразовывать форматы и т.д.
- **Интеграция**: Передаёт данные в Elasticsearch или другие системы для дальнейшего анализа.

**Пример использования**: Logstash может собирать логи Nginx, извлекать из них IP-адреса, HTTP-методы и коды ответов, а затем отправлять структурированные данные в Elasticsearch для анализа в Kibana.

#### Преимущества Logstash:

- **Гибкость**: Поддерживает множество источников данных (файлы, syslog, Beats, Kafka и т.д.) и плагинов для обработки.
- **Мощные фильтры**: Grok, mutate, geoip и другие фильтры позволяют глубоко обрабатывать логи.
- **Интеграция с ELK**: Простая совместимость с Elasticsearch и Kibana.
- **Поддержка сложных сценариев**: Может обрабатывать многострочные логи, JSON, CSV и другие форматы.
- **Открытый исходный код**: Бесплатен и имеет активное сообщество.

#### Недостатки Logstash:

- **Высокое потребление ресурсов**: Logstash, написанный на JRuby, может быть тяжеловесным, особенно при большом количестве логов, что требует значительных вычислительных ресурсов (CPU, RAM).[
    
    ![](https://imgs.search.brave.com/5-sb8BSsXU8FQfWBZ2L4IQ8A-l_DgA731J5-wx8Duag/rs:fit:64:0:0:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNzdiOGJkOGIw/Y2QxZGNkOTQzMTlj/YWI3MWQzNzgzZDk4/MmIzZDc5MjNkNTM2/ZWE3NzZhMzhjNmU1/MTEzODczMy9vbmxh/bnRhLnJ1Lw)
    
    ](https://onlanta.ru/press/blog/nash-put-k-centralizovannomu-hraneniju-logov/)[
    
    ![](https://imgs.search.brave.com/PmNCEE7WHH78owRm4W2zLVLhvjj2jBZB2RyniMM-w3Y/rs:fit:64:0:0:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvYmI1ZTI1NmUy/MTc1ODVkODlkODAw/MzA1ZjcyMTlmNzVk/MzljMWU1ZmRiODlh/ZDg2NzkwNWVlOWYy/NzIyMTYwNy9oYWJy/LmNvbS8)
    
    ](https://habr.com/ru/companies/slurm/articles/517636/)
- **Сложность настройки**: Конфигурационные файлы могут быть сложными для новичков, особенно при использовании сложных фильтров.
- **Задержки в обработке**: При высокой нагрузке может возникать очередь, что замедляет обработку логов.[
    
    ![](https://imgs.search.brave.com/PmNCEE7WHH78owRm4W2zLVLhvjj2jBZB2RyniMM-w3Y/rs:fit:64:0:0:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvYmI1ZTI1NmUy/MTc1ODVkODlkODAw/MzA1ZjcyMTlmNzVk/MzljMWU1ZmRiODlh/ZDg2NzkwNWVlOWYy/NzIyMTYwNy9oYWJy/LmNvbS8)
    
    ](https://habr.com/ru/articles/708278/)
- **Неэффективность для лёгких задач**: Для простого сбора логов может быть избыточным, так как существуют более лёгкие альтернативы, такие как Filebeat или Fluent Bit.

---

### 4. Что такое Filebeat?

**Filebeat** — это лёгкий агент с открытым исходным кодом из семейства Beats, разработанный компанией Elastic. Он предназначен для чтения логов из файлов и отправки их в Logstash или напрямую в Elasticsearch.

**Основные функции Filebeat:**

- Читает логи построчно из указанных файлов (например, /var/log/nginx/access.log).
- Отслеживает изменения в файлах (поддерживает ротацию логов).
- Отправляет данные в Logstash или Elasticsearch.
- Поддерживает модули для упрощённой настройки сбора логов популярных сервисов (Nginx, Apache, MySQL и т.д.).
- Может добавлять метаданные (например, имя хоста, теги).

**Пример конфигурации Filebeat**:

yaml

СвернутьПеренос

Копировать

`filebeat.inputs: - type: log enabled: true paths: - /var/log/nginx/access.log fields: type: nginx output.logstash: hosts: ["logstash:5044"]`

**Зачем нужен Filebeat?**

- Используется для сбора логов с серверов и их передачи в централизованную систему (Logstash/Elasticsearch).
- Подходит для сценариев, где требуется минимальная нагрузка на систему.

---

### 5. Что такое Fluent Bit?

**Fluent Bit** — это лёгкий и высокопроизводительный сборщик и процессор логов, разработанный как часть проекта Fluentd, но оптимизированный для минимального потребления ресурсов. Он предназначен для сбора, обработки и передачи логов и метрик в различные системы, включая Elasticsearch, Fluentd, Kafka и другие.

**Основные функции Fluent Bit:**

- Сбор логов из файлов, systemd, Docker, Kubernetes и других источников.
- Поддержка базовых фильтров (парсинг JSON, модификация данных).
- Высокая производительность и низкое потребление ресурсов (около 150 КБ памяти против 20 МБ для Fluentd).[
    
    ![](https://imgs.search.brave.com/PmNCEE7WHH78owRm4W2zLVLhvjj2jBZB2RyniMM-w3Y/rs:fit:64:0:0:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvYmI1ZTI1NmUy/MTc1ODVkODlkODAw/MzA1ZjcyMTlmNzVk/MzljMWU1ZmRiODlh/ZDg2NzkwNWVlOWYy/NzIyMTYwNy9oYWJy/LmNvbS8)
    
    ](https://habr.com/ru/companies/slurm/articles/517636/)
- Поддержка плагинов для расширения функциональности.

**Пример конфигурации Fluent Bit**:

ini

СвернутьПеренос

Копировать

`[INPUT] Name tail Path /var/log/nginx/access.log Tag nginx.access [FILTER] Name parser Match nginx.access Key_Name log Parser nginx [OUTPUT] Name elasticsearch Match nginx.access Host elasticsearch Port 9200 Index nginx`

**Зачем нужен Fluent Bit?**

- Используется в сценариях, где важна высокая производительность и минимальное потребление ресурсов, например, в Kubernetes или IoT-устройствах.
- Заменяет Logstash в стеке EFK (Elasticsearch, Fluent Bit, Kibana) для упрощения архитектуры.

---

### 6. Различия между Filebeat и Fluent Bit

|**Характеристика**|**Filebeat**|**Fluent Bit**|
|---|---|---|
|**Происхождение**|Часть экосистемы Elastic (Beats)|Часть экосистемы Fluentd, независимый проект|
|**Язык разработки**|Написан на Go, лёгкий и эффективный|Написан на C, ещё более лёгкий и производительный|
|**Потребление ресурсов**|Низкое (~10-20 МБ памяти)|Очень низкое (~150 КБ памяти)|
|**Функциональность**|Основной фокус — сбор и отправка логов, минимальная обработка|Сбор, фильтрация и отправка логов, поддержка более сложной обработки|
|**Фильтры**|Ограниченные возможности обработки (например, multiline, add_fields)|Более мощные фильтры (парсинг JSON, Lua-скрипты, регулярные выражения)|
|**Интеграция**|Тесная интеграция с ELK-стеком (Logstash, Elasticsearch, Kibana)|Универсальная, работает с Elasticsearch, Fluentd, Kafka и другими системами|
|**Модули**|Готовые модули для популярных сервисов (Nginx, Apache, MySQL)|Меньше готовых модулей, но гибкая настройка через плагины|
|**Производительность**|Хорошая, но ниже, чем у Fluent Bit при высоких нагрузках|Высокая, оптимизирована для больших объёмов данных и embedded-систем|
|**Сценарии использования**|Централизованный сбор логов в ELK-стеке, простые сценарии|Высоконагруженные системы, Kubernetes, IoT, сценарии с минимальными ресурсами|
|**Поддержка multiline**|Хорошая поддержка многострочных логов на уровне агента|Поддержка есть, но требует настройки фильтров|

**Ключевые различия**:

- **Filebeat** лучше подходит для сценариев, где требуется простая отправка логов в ELK-стек с минимальной настройкой. Он оптимизирован для интеграции с Logstash и Elasticsearch и имеет готовые модули для популярных сервисов.
- **Fluent Bit** предпочтителен в высоконагруженных или ресурсоограниченных средах (например, Kubernetes, IoT). Он более гибкий в плане обработки данных и интеграции с разными системами, но требует больше ручной настройки.

**Вывод**:

- Используйте **Filebeat**, если вы работаете в экосистеме ELK и вам нужна простота и готовые модули.
- Используйте **Fluent Bit**, если важна максимальная производительность, минимальное потребление ресурсов или интеграция с не-ELK системами (например, в стеке EFK).
## Второй блок
###   
1. Чем Fluent Bit отличается от Fluentd?

**Fluent Bit** и **Fluentd** — это инструменты для сбора, обработки и передачи логов, разработанные в рамках экосистемы Fluentd, но они имеют разные цели и сценарии использования. Вот их основные различия:

|**Характеристика**|**Fluent Bit**|**Fluentd**|
|---|---|---|
|**Язык разработки**|Написан на C, что делает его лёгким и высокопроизводительным|Написан на Ruby, более тяжеловесный|
|**Потребление ресурсов**|Очень низкое (~150-450 КБ памяти)|Высокое (~20-40 МБ памяти и более)|
|**Производительность**|Высокая, оптимизирован для больших объёмов данных и ограниченных ресурсов|Хорошая, но ниже, чем у Fluent Bit, из-за Ruby и большего оверхеда|
|**Функциональность**|Сбор, базовая фильтрация и передача логов, минималистичный подход|Полнофункциональный, с мощными возможностями обработки и плагинами|
|**Фильтры и плагины**|Ограниченный набор фильтров (JSON, regex, Lua), меньше плагинов|Богатый набор плагинов (более 1000) для сложной обработки и интеграций|
|**Сценарии использования**|IoT, Kubernetes, embedded-системы, высоконагруженные окружения|Централизованный сбор логов, сложные сценарии обработки, enterprise-системы|
|**Поддержка multiline**|Ограниченная, требует настройки фильтров|Хорошая встроенная поддержка многострочных логов|
|**Интеграция**|Универсальная (Elasticsearch, Kafka, Fluentd и др.)|Широкая интеграция, часто используется как центральный агрегатор логов|
|**Размер бинарника**|Компактный (~1-2 МБ)|Значительно больше (~50 МБ)|
|**Сообщество и экосистема**|Активно развивается, но менее зрелая экосистема|Зрелая экосистема с большим количеством плагинов и сообществом|

**Ключевые различия**:

- **Fluent Bit** — это лёгкий и производительный инструмент, оптимизированный для сбора и передачи логов в условиях ограниченных ресурсов (например, в Kubernetes или IoT). Он подходит для простых сценариев, где требуется минимальная обработка.
- **Fluentd** — более тяжеловесный и функциональный, предназначен для сложных сценариев, где требуется глубокая обработка логов (например, агрегация, сложные трансформации, интеграция с множеством систем).

**Когда выбирать**:

- **Fluent Bit**: Для edge-устройств, контейнеров, или когда важна минимальная нагрузка на ресурсы.
- **Fluentd**: Для центрального сервера логов, где нужна мощная обработка и поддержка множества источников/выходов.

---

### 2. Что такое Grafana Loki?

**Grafana Loki** — это система логирования с открытым исходным кодом, разработанная Grafana Labs. Она предназначена для эффективного хранения и анализа логов, особенно в облачных и контейнерных средах (например, Kubernetes). Loki оптимизирован для работы с метками (labels), что делает его похожим на Prometheus для логов.

**Основные особенности Loki**:

- **Хранение логов с метками**: Логи индексируются не по содержимому, а по меткам (например, app=frontend, env=prod), что снижает затраты на индексацию и ускоряет поиск.
- **Интеграция с Grafana**: Логи визуализируются через интерфейс Grafana, что позволяет комбинировать логи с метриками (например, из Prometheus).
- **Эффективность хранения**: Использует сжатие и хранит логи в объектных хранилищах (S3, GCS) или локально, что делает его экономичным.
- **LogQL**: Собственный язык запросов для фильтрации и анализа логов.
- **Агенты**: Логи собираются с помощью агентов, таких как Promtail, Fluent Bit или Fluentd.

**Зачем нужен Loki?**

- Для централизованного хранения логов с минимальными затратами на ресурсы.
- Для интеграции с Grafana для создания дашбордов, где логи и метрики отображаются вместе.
- Для работы в Kubernetes, где метки (labels) упрощают управление логами контейнеров.

**Пример использования**:

- Сбор логов из Kubernetes-подов с помощью Promtail, их хранение в Loki и визуализация через Grafana.

**Преимущества**:

- Лёгкий и экономичный по сравнению с ELK-стеком.
- Простая интеграция с Grafana и Prometheus.
- Эффективен для больших объёмов логов благодаря индексации по меткам.

**Недостатки**:

- Меньше возможностей для сложной обработки логов по сравнению с Logstash.
- Поиск по содержимому логов менее эффективен, так как индексируются только метки.
- Меньше плагинов и интеграций, чем у Fluentd или ELK.

---

### 3. Как настроить автоматический сбор логов из всех Docker-контейнеров (уже запущенных и новых) на определенном хосте и отправку в Elasticsearch?

Для автоматического сбора логов из всех Docker-контейнеров (включая уже запущенные и новые) на хосте и отправки их в Elasticsearch можно использовать **Fluent Bit**, так как он лёгкий, производительный и хорошо интегрируется с Docker и Elasticsearch. Вот пошаговая инструкция:

#### Шаг 1: Установите Fluent Bit

1. **Скачайте Fluent Bit**:
    - Для Ubuntu/Debian:
        
        bash
        
        СвернутьПереносИсполнить
        
        Копировать
        
        `curl https://raw.githubusercontent.com/fluent/fluent-bit/master/install.sh | sh`
        
    - Или используйте пакетный менеджер:
        
        bash
        
        СвернутьПереносИсполнить
        
        Копировать
        
        `sudo apt-get install fluent-bit`
        
2. **Запустите Fluent Bit** как сервис:
    
    bash
    
    СвернутьПереносИсполнить
    
    Копировать
    
    `sudo systemctl enable fluent-bit sudo systemctl start fluent-bit`
    

#### Шаг 2: Настройте Fluent Bit для сбора логов Docker

Fluent Bit использует плагин docker для чтения логов из Docker через его API. Логи Docker обычно хранятся в /var/lib/docker/containers/*/*.log.

1. **Создайте конфигурационный файл** /etc/fluent-bit/fluent-bit.conf:
    
    ini
    
    СвернутьПеренос
    
    Копировать
    
    `[SERVICE] Flush 1 Log_Level info Daemon off Parsers_File parsers.conf [INPUT] Name tail Tag docker.* Path /var/lib/docker/containers/*/*.log Parser docker Refresh_Interval 5 Mem_Buf_Limit 5MB Skip_Long_Lines On [FILTER] Name modify Match docker.* Add source docker [OUTPUT] Name elasticsearch Match docker.* Host elasticsearch Port 9200 Index docker_logs Type _doc Retry_Limit False Suppress_Type_Name On`
    
2. **Создайте файл парсеров** /etc/fluent-bit/parsers.conf:
    
    ini
    
    СвернутьПеренос
    
    Копировать
    
    `[PARSER] Name docker Format json Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%L Time_Keep On`
    

**Объяснение конфигурации**:

- [INPUT]:
    - Name tail: Читает логи из файлов.
    - Path /var/lib/docker/containers/*/*.log: Указывает путь к логам всех контейнеров.
    - Parser docker: Применяет парсер для JSON-логов Docker.
    - Refresh_Interval 5: Проверяет новые файлы логов каждые 5 секунд.
- [FILTER]:
    - Добавляет поле source: docker для идентификации логов.
- [OUTPUT]:
    - Отправляет логи в Elasticsearch на хост elasticsearch, порт 9200, в индекс docker_logs.
- [PARSER]:
    - Парсер docker обрабатывает JSON-логи Docker, извлекая временные метки.

#### Шаг 3: Настройте доступ Fluent Bit к Docker

Fluent Bit должен иметь доступ к Docker сокету (/var/run/docker.sock) для получения метаданных о контейнерах (например, имени контейнера, меток).

1. **Добавьте Fluent Bit в группу docker**:
    
    bash
    
    СвернутьПереносИсполнить
    
    Копировать
    
    `sudo usermod -aG docker fluent-bit`
    
2. **Проверьте права доступа**:
    
    bash
    
    СвернутьПереносИсполнить
    
    Копировать
    
    `sudo chown fluent-bit:fluent-bit /var/run/docker.sock sudo chmod 660 /var/run/docker.sock`
    

#### Шаг 4: Настройте Elasticsearch

1. Убедитесь, что Elasticsearch запущен и доступен по адресу elasticsearch:9200.
2. Проверьте, что индекс docker_logs создаётся автоматически или создайте его вручную:
    
    bash
    
    СвернутьПереносИсполнить
    
    Копировать
    
    `curl -X PUT "http://elasticsearch:9200/docker_logs" -H 'Content-Type: application/json' -d '{}'`
    

#### Шаг 5: Перезапустите Fluent Bit

bash

СвернутьПереносИсполнить

Копировать

`sudo systemctl restart fluent-bit`

#### Шаг 6: (Опционально) Настройте Kibana для визуализации

1. Подключите Kibana к Elasticsearch.
2. Создайте индекс-паттерн для docker_logs в Kibana:
    - Перейдите в Kibana → Stack Management → Index Patterns → Create Index Pattern.
    - Укажите docker_logs и выберите поле времени (@timestamp).
3. Используйте Kibana для поиска и визуализации логов.

#### Шаг 7: Проверка

1. Проверьте статус Fluent Bit:
    
    bash
    
    СвернутьПереносИсполнить
    
    Копировать
    
    `sudo systemctl status fluent-bit`
    
2. Убедитесь, что логи поступают в Elasticsearch:
    
    bash
    
    СвернутьПереносИсполнить
    
    Копировать
    
    `curl -X GET "http://elasticsearch:9200/docker_logs/_search?pretty"`
    

#### Шаг 8: Автоматический сбор для новых контейнеров

Конфигурация Path /var/lib/docker/containers/*/*.log автоматически включает логи новых контейнеров, так как Fluent Bit отслеживает новые файлы в этой директории через Refresh_Interval.

#### Дополнительные советы

- **Обогащение метаданными**: Используйте плагин kubernetes в Fluent Bit, если контейнеры работают в Kubernetes, чтобы добавлять метки подов и неймспейсов.
- **Обработка ошибок**: Настройте буферизацию (Buffer_Chunk_Size, Buffer_Max_Size) для устойчивости к сбоям сети.
- **Безопасность**: Настройте TLS для соединения с Elasticsearch, если он находится в другой сети.

**Пример обогащённой конфигурации для метаданных**:

ini

СвернутьПеренос

Копировать

`[INPUT] Name tail Tag docker.* Path /var/lib/docker/containers/*/*.log Parser docker Refresh_Interval 5 Mem_Buf_Limit 5MB Skip_Long_Lines On Docker_Mode On Docker_Mode_Parser docker [FILTER] Name kubernetes Match docker.* Kube_URL https://kubernetes.default.svc:443 Kube_CA_File /var/run/secrets/kubernetes.io/serviceaccount/ca.crt Kube_Token_File /var/run/secrets/kubernetes.io/serviceaccount/token [OUTPUT] Name elasticsearch Match docker.* Host elasticsearch Port 9200 Index docker_logs Type _doc`
## Третий блок
### Пошаговая инструкция по настройке автоматического сбора логов в Kubernetes

#### Шаг 1: Убедитесь, что у вас есть доступ к кластеру Kubernetes и Elasticsearch

- Убедитесь, что кластер Kubernetes доступен (например, через kubectl).
- Проверьте, что Elasticsearch работает и доступен по адресу (например, elasticsearch:9200).
- Если Elasticsearch защищён, подготовьте учётные данные или TLS-сертификаты.

#### Шаг 2: Установите Fluent Bit как DaemonSet

Fluent Bit будет развёрнут как DaemonSet, чтобы агент работал на каждом узле кластера и собирал логи всех контейнеров через их лог-файлы, которые Kubernetes хранит в /var/log/containers/*.log.

1. **Создайте namespace для Fluent Bit** (опционально):
    
    bash
    
    СвернутьПереносИсполнить
    
    Копировать
    
    `kubectl create namespace logging`
    
2. **Создайте манифест для Fluent Bit**: Создайте файл fluent-bit-ds.yaml со следующим содержимым:
    
    yaml
    
    СвернутьПеренос
    
    Копировать
    
    `apiVersion: v1 kind: ConfigMap metadata: name: fluent-bit-config namespace: logging labels: app: fluent-bit data: fluent-bit.conf: | [SERVICE] Flush 1 Log_Level info Daemon off Parsers_File parsers.conf HTTP_Server On HTTP_Listen 0.0.0.0 HTTP_Port 2020 [INPUT] Name tail Tag kube.* Path /var/log/containers/*.log Parser docker DB /var/log/flb_kube.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 [FILTER] Name kubernetes Match kube.* Kube_URL https://kubernetes.default.svc:443 Kube_CA_File /var/run/secrets/kubernetes.io/serviceaccount/ca.crt Kube_Token_File /var/run/secrets/kubernetes.io/serviceaccount/token Merge_Log On Keep_Log Off K8s-Logging.Parser On K8s-Logging.Exclude Off [OUTPUT] Name elasticsearch Match kube.* Host elasticsearch Port 9200 Index kubernetes_logs Type _doc Retry_Limit False Suppress_Type_Name On parsers.conf: | [PARSER] Name docker Format json Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%L Time_Keep On --- apiVersion: apps/v1 kind: DaemonSet metadata: name: fluent-bit namespace: logging labels: app: fluent-bit spec: selector: matchLabels: app: fluent-bit template: metadata: labels: app: fluent-bit spec: containers: - name: fluent-bit image: fluent/fluent-bit:3.1 resources: limits: memory: 200Mi cpu: 500m requests: memory: 100Mi cpu: 100m volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker readOnly: true - name: fluent-bit-config mountPath: /fluent-bit/etc/fluent-bit.conf subPath: fluent-bit.conf - name: fluent-bit-config mountPath: /fluent-bit/etc/parsers.conf subPath: parsers.conf volumes: - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers - name: fluent-bit-config configMap: name: fluent-bit-config serviceAccountName: fluent-bit tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule - key: node-role.kubernetes.io/control-plane`
    

### -plane effect: NoSchedule

### apiVersion: v1 kind: ServiceAccount metadata: name: fluent-bit namespace: logging

apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: fluent-bit-role role: ClusterRole metadata: name: fluent-role rules:

- apiGroups: [""] resources: ["namespaces", "pods"] verbs: ["get", "list", "watch"]

---

apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: fluent-bit-role-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: fluent-bit-role subjects:

- kind: ServiceAccount name: fluent-bit namespace: logging

text

СвернутьПеренос

Копировать

``**Объяснение манифеста**: - **ConfigMap**: Содержит конфигурацию Fluent Bit: - `[INPUT]`: Читает логи из `/var/log/containers/*.log` (символические ссылки на логи контейнеров). - `[FILTER]`: Использует плагин `kubernetes` для обогащения логов метаданными (имя пода, namespace, labels). - `[OUTPUT]`: Отправляет логи в PostgreSQL в индекс `kubernetes_logs`. - **DaemonSet**: Разворачивает Fluent Bit на каждом узле кластера. - Монтирует пути `/var/log` и `/var/lib/docker/containers` для доступа к логам. - Использует ConfigMap для конфигурации. - **ServiceAccount и RBAC-правила**: Дают Fluent Bit доступ к API Kubernetes для получения метаданных о подах. - **Шаг 3**: Примените манифест**: ```bash kubectl apply -f fluent-bit-ds.yaml``

#### Шаг 4: Проверьте работу Fluent Bit

1. Убедитесь, что поды Fluent Bit запущены:
    
    bash
    
    СвернутьПереносИсполнить
    
    Копировать
    
    `kubectl get pods -n logging`
    
2. Проверьте логи Fluent Bit для диагностики:
    
    bash
    
    СвернутьПереносИсполнить
    
    Копировать
    
    `kubectl logs -n logging -l app=fluent-bit`
    
3. Проверьте, что логи поступают в Elasticsearch:
    
    bash
    
    СвернутьПереносИсполнить
    
    Копировать
    
    `curl -X GET "http://<elasticsearch>:9200/kubernetes_logs/_search?pretty=true"`
    

#### Шаг 5: (Опционально) Настройте Kibana для визуализации

1. Подключите Kibana к Elasticsearch.
2. Создайте индекс-паттерн для kubernetes_logs в Kibana:
    - Перейдите в Kibana → **Stack Management** → **Index Patterns** → **Create Index Pattern**.
    - Укажите kubernetes_logs и выберите поле времени (@timestamp).
3. Используйте Kibana для поиска и визуализации логов, фильтруя по kubernetes.namespace_name, kubernetes.pod_name, или другим метаданным.

#### Шаг 6: Автоматизация для новых подов/контейнеров

- Конфигурация Path /var/log/containers/*.log автоматически включает новые поды и поды, так как Fluent Bit отслеживает новые файлы через Refresh_Interval.
- Плагин kubernetes динамически обогащает логи метаданными новых подов через API Kubernetes.

#### Шаг 7: Дополнительные настройки (опционально)

1. **Обработка многострочных логов** (например, для Java-приложений): Добавьте в parsers.conf парсер для многострочных логов:
    
    ini
    
    СвернутьПеренос
    
    Копировать
    
    `[PARSER] NAME multi_line Format regex Regex ^(?<log>.*)$ Multi_line_FirstLine ^\d{4}-\d{2}-\d{2}\s Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%L`
    
    И обновите [INPUT] в fluent-bit.conf:
    
    ini
    
    СвернутьПеренос
    
    Копировать
    
    `[INPUT] Name tail Tag kube.* Path /var/log/containers/*.log Parser multi_line Multiline On Multiline_Key multi_line`
    
2. **Безопасность**:
    - Настройте TLS для соединения с Elasticsearch:
        
        ini
        
        СвернутьПеренос
        
        Копировать
        
        `[OUTPUT] Name elasticsearch Match kube.* Host elasticsearch Port 9200 TLS On TLS_CA_File /path/to/ca.crt TLS_Crt_File /path/to/cert.crt TLS_Key_File /path/to/key.key`
        
    - Используйте секреты Kubernetes для хранения учётных данных:
        
        undefined
        

apiVersion: v1 kind: Secret metadata: name: elasticsearch-credentials namespace: logging data: username: <base64_encoded> password: <base64_encoded>

text

СвернутьПеренос

Копировать

`3. **Буферизация для устойчивости**: ```ini [SERVICE] Storage_Path /var/log/fluent-bit-storage/ Storage_Sync Normal Storage_Checksum Off Storage_Backlog_Mem_Limit 10M`

4. **Фильтрация логов**: Исключите логи системных подов (например, из namespace kube-system):
    
    ini
    
    СвернутьПеренос
    
    Копировать
    
    `[FILTER] Name kubernetes_exclude Match kube.* Kube_Namespace_Regex kube-system Exclude On`
    

#### Шаг 8: Проверка и мониторинг

- Используйте Kibana для проверки, что логи содержат метаданные (kubernetes.namespace_name, kubernetes.pod_name, kubernetes.container_name).
- Мониторьте потребление ресурсов Fluent Bit:
    
    bash
    
    СвернутьПереносИсполнить
    
    Копировать
    
    `kubectl top pod -n logging`
    

---

### Альтернативы

- **Fluentd**: Если требуется более сложная обработка логов, можно использовать Fluentd` вместо Fluent Bit, но он потребляет больше ресурсов.
- **Loki + Promtail**: Для экономичного хранения логов и интеграции с Grafana.
- **Elastic Agent**: Альтернатива от Elastic, но менее гибкая в настройках.

---

### Примечания

- Убедитесь, что пути /var/log/containers и /var/lib/docker/containers доступны вашему драйверу логирования Docker (например, используется json-file).
- Если вы используете CRI-O или containerd, путь к логам может отличаться (например, /var/log/pods/*/*.log). Обновите Path в конфигурации.
- Для больших кластеров настройте буферизацию и лимиты ресурсов, чтобы избежать перегрузки.